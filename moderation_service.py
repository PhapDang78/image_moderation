# moderation_service.py (Phi√™n b·∫£n FIX l·ªói ModuleNotFoundError)

import os
from fastapi import FastAPI, UploadFile, File, HTTPException, status
from dotenv import load_dotenv
from clarifai.client.model import Model
# üö® ƒê√É S·ª¨A: Import ClarifaiException theo c√°ch m·ªõi trong SDK 11.x
from clarifai.errors import ApiError as ClarifaiException


# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

app = FastAPI(
    title="Clarifai Image Moderation Service",
    description="Microservice s·ª≠ d·ª•ng Clarifai ƒë·ªÉ ki·ªÉm duy·ªát n·ªôi dung h√¨nh ·∫£nh."
)

# --- C·∫•u h√¨nh Clarifai ---
CLARIFI_API_KEY = os.getenv("CLARIFAI_API_KEY")
MODEL_URL = "https://clarifai.com/clarifai/main/models/moderation-recognition"
UNSAFE_THRESHOLD = 0.8  # Ng∆∞·ª°ng an to√†n (80%)

BLOCKING_LABELS = ['suggestive', 'gore', 'drugs', 'hate', 'unsafe'] 

clarifai_model = None

# Kh·ªüi t·∫°o Clarifai Model Client
try:
    if not CLARIFI_API_KEY:
        # Ki·ªÉm tra API Key (c√≥ th·ªÉ b·ªè qua n·∫øu b·∫°n d√πng PAT)
        raise ValueError("CLARIFI_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p.")
    
    clarifai_model = Model(MODEL_URL, pat=CLARIFI_API_KEY)
    print("‚úÖ Clarifai Model Client ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.")
    
except Exception as e:
    print(f"‚ùå L·ªói khi kh·ªüi t·∫°o Clarifai: {e}")
    pass


# --- Endpoint Ki·ªÉm duy·ªát H√¨nh ·∫£nh ---
@app.post("/api/v1/image/moderation")
async def check_image_moderation(image: UploadFile = File(...)):
    if not clarifai_model:
        return {"is_unsafe": False, "message": "Moderation service is inactive or failed to initialize."}

    # ƒê·ªçc d·ªØ li·ªáu ·∫£nh th√†nh bytes
    try:
        image_bytes = await image.read()
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Kh√¥ng th·ªÉ ƒë·ªçc file: {e}"
        )

    # 1. G·ªåI V√Ä B·∫ÆT L·ªñI CLARIFAI
    try:
        response = clarifai_model.predict_by_bytes(
            image_bytes, 
            input_type="image"
        )
    except ClarifaiException as e:
        # B·∫Øt l·ªói c·ª• th·ªÉ t·ª´ Clarifai API
        print(f"L·ªói Clarifai API: {e}")
        return {"is_unsafe": False, "message": f"API check failed due to Clarifai error: {e}"}
    except Exception as e:
        # B·∫Øt l·ªói network ho·∫∑c I/O kh√°c trong qu√° tr√¨nh g·ªçi API
        print(f"L·ªói g·ªçi API: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"L·ªói trong qu√° tr√¨nh g·ªçi Clarifai API: {e}"
        )
        

    # 2. X·ª¨ L√ù K·∫æT QU·∫¢ V√Ä RAISE HTTP 403
    
    if not response.outputs or not response.outputs[0].data.concepts:
        print("Ph·∫£n h·ªìi Clarifai kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng c√≥ k·∫øt qu·∫£.")
        return {"is_unsafe": False, "message": "Clarifai response was invalid."}


    concepts = response.outputs[0].data.concepts
    
    is_unsafe = False
    max_score = 0.0
    unsafe_labels = []

    for concept in concepts:
        score = concept.value 
        name = concept.name
        
        if score >= UNSAFE_THRESHOLD:
            max_score = max(max_score, score)
            unsafe_labels.append({"name": name, "score": score})
            
            if name in BLOCKING_LABELS: 
                is_unsafe = True

    if is_unsafe:
        # FastAPI t·ª± x·ª≠ l√Ω HTTPException n√†y, kh√¥ng c·∫ßn except
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail={
                "message": "Image failed moderation check: Unsafe content detected.",
                "unsafe_score": max_score,
                "unsafe_labels": unsafe_labels
            }
        )

    return {
        "is_unsafe": False, 
        "unsafe_score": max_score, 
        "unsafe_labels": unsafe_labels
    }


# --- Ch·∫°y Server ---
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)